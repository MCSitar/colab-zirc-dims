{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yL0b7kBpW1Le",
        "m5ArNymvS7py",
        "MJJNBEJrZyFC",
        "IpH7ZSF1gF3m",
        "nLexmQmbmP9L",
        "Vj4IX9Rll27E"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0dY5QyIbASi"
      },
      "source": [
        "# Automatic and Semi-Automatic Grain Measurement Notebook for Non-ALC Datasets\n",
        "The code in this Jupyter/Google Colab notebook will automatically detect, segment, and measure heavy mineral grains in reflected light, grain-centered, single-shot images saved during LA-ICP-MS analyses at facilities using Chromium targeting software. Grain segmentation is accomplished via trained deep learning models, using the Detectron2 deep learning library. Images for segmentation will ideally have been saved with scaling metadata files during LA-ICP-MS dating (e.g., at the [UCSB Petrochronology Facility](https://www.petrochronology.com/)), but scaling information for images can be added manually for images without metadata.\n",
        "\n",
        "This Notebook is ready-to-run and implements code available in the [colab-zirc-dims GitHub repository](https://github.com/MCSitar/colab_zirc_dims). This notebook can be run in Gooogle Colab or, if downloaded, as a regular Jupyter notebook in a local Anaconda environment. If running in Google Colab, it should be opened in playground mode or copied into users' Google Drives before running. Make sure that you are connected to a GPU runtime when running this notebook in Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to run this Notebook (for new Google Colab users):"
      ],
      "metadata": {
        "id": "yL0b7kBpW1Le"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab notebooks are Jupyter notebooks that execute in cloud-hosted Python 3 environments on virtual machines equiped with high-end CPUs and GPUs. Users are thus able to run compute-intensive Python code, view outputs, etc. in a browser window from any local computer regardless of their hardware and without any setup or installation.\n",
        "\n"
      ],
      "metadata": {
        "id": "AKJMCMF4XKtu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking GPU runtime:"
      ],
      "metadata": {
        "id": "MdNJ-uIYbSi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code in this Notebook uses RCNN models to segment zircon crystals from images, so virtual runtimes executing it require access to a GPU. This should be enabled by default, but if users want to verify that their virutal machine has a GPU:\n",
        "\n",
        "1.   Navigate to 'Runtime' --> 'Change runtime type' in the toolbar at the top of the screen.\n",
        "2.   In the 'Notebook Settings' window that pops up, check that 'GPU' is selected in the 'Hardware accelerator' dropdown menu. If not, select it.\n",
        "3.   Click save, then run the Notebook.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I7jCAFt5baTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Running cells:"
      ],
      "metadata": {
        "id": "PO9ZCoHDeMKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebooks are made up of cells containing either text or code. Cells with code in this Notebook should be run in top-bottom order unless otherwise specified. To run cells:\n",
        "\n",
        "1.   Hover the mouse over the cell to be run, then click the button with a 'play' symbol on it. See below for an example:"
      ],
      "metadata": {
        "id": "dGkFQ6mNeMKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Try running this example cell\n",
        "print('Cell run!')"
      ],
      "metadata": {
        "id": "y0LoYb_Mf4CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clearing outputs:"
      ],
      "metadata": {
        "id": "CtUo23yWgInW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make this Notebook look neater after running it and/or to cut down on file size before saving (e.g., if there are many inspection images open), users can clear all cell outputs. To do this:\n",
        "\n",
        "1.   Navigate to 'Edit' --> 'Clear all outputs' in the toolbar at the top of the screen, then click."
      ],
      "metadata": {
        "id": "bQ0mP2FJgpQj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Factory reset runtime (in case of crashes):"
      ],
      "metadata": {
        "id": "z_Qzu57xhvrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some earlier versions of this project had memory leak issues that caused RAM crashes during fully-automated grain processing. Said issues seem to be fixed, but if they reappear:\n",
        "\n",
        "1.   Clear the current virtual machine runtime and connect to a new one (with fresh RAM) by navigating to 'Runtime' --> 'Factory reset runtime' and clicking.\n",
        "2.   Re-run all neccesary cells in Notebook.\n",
        "3.   (Please) open an issue on the project Github page or use the contact details found there to report the bug directly to the project manager.\n"
      ],
      "metadata": {
        "id": "9nCcoQ_xh2xO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Restarting in Case of Runtime Auto-Disconnect:"
      ],
      "metadata": {
        "id": "m5ArNymvS7py"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab notebooks give users access to virtual machines with cloud-based GPUs and CPUs provided by Google. Because Google does not like it when their cloud computing resources are being allocated but not actually used, Colab runtimes will automatically disconnect and end if left completely idle (i.e., no code running and no mouse movement) for more than ~30 minutes or after 12 hours of continuous use. Paid versions of Colab are more lenient but are unlikely to be worthwhile for most colab_zirc_dims users.\n",
        "\n",
        "Colab will explicitly tell users if their runtime has been disconnected via popup window. The crash warning that may appear after automated runtime *restart* in the first code cell below is notably not an actual *disconnect* popup - this warning should be ignored.\n",
        "\n",
        "Potential auto-disconnect-related issues are mitigated in colab_zirc_dims through automated per-sample saving to Google Drive during fully and semi-automated processing; disconnected users are able to restart processing from the sample that was being processed at time of disconnect. Disconnected users must, however, re-run all pre-processing cells before resuming processing. Detailed instructions for resuming processing post-disconnect in specific cases are below:"
      ],
      "metadata": {
        "id": "mPgjB6ylTRlJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Disconnect prior to processing:"
      ],
      "metadata": {
        "id": "MJJNBEJrZyFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No data will have been lost in this case because no data will have been processed. To resume work:\n",
        "\n",
        "1.   Reconnect to the notebook\n",
        "2.   (Optionally) clear cell outputs so that outputs from the previous session are not mixed with fresh outputs - see \"How to run this Notebook...\" above for instructions.\n",
        "3.   Re-run the notebook from the first code cell.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1h2GBZVAdX8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Disconnect during fully automated processing:"
      ],
      "metadata": {
        "id": "IpH7ZSF1gF3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This scenario is unlikely given that Colab notebooks provide ~12 hours of connection time before timeout while compute resources are being utilized. If it does occur:\n",
        "\n",
        "1.   Check the automated processing cell outputs to identify the sample that the notebook was processing when it disconnected. This will be the sample that you restart processing from.\n",
        "2.   Reconnect to the notebook.\n",
        "3.   (Optionally) clear cell outputs so that outputs from the previous session are not mixed with fresh outputs - see \"How to run this Notebook...\" above for instructions.\n",
        "4.   Re-run installation and sample loading cells from the first code cell.\n",
        "5.   In the sample selection UI, select all samples including and subsequent to the sample (step 1) that was being processed upon disconnect.\n",
        "6.   Run model download and initialization cells, then restart automated processing to finish measuring grains in the remaining samples of your dataset.\n",
        "7.   (Optional) If you want to continue to semi-automated segmentation of your dataset using grain polygons saved during automated processing, you will need to combine these saved polygons into a single 'output' directory. To do so, simply move the per-sample polygon .json files from the 'saved_polygons' sub-directory of one incomplete processing output directory (found in the '/outputs' sub-directory of your project directory) into the 'saved_polygons' sub-directory of the other incomplete output directory. Before running the GUI, load polygons from the output directory where you combined the polygon .json files using the second 'loading' cell."
      ],
      "metadata": {
        "id": "s7JYZUUIgF3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Disconnect during semi-automated processing:"
      ],
      "metadata": {
        "id": "nLexmQmbmP9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this (much more likely) scenario, only user-generated polygons from the sample being processed prior to disconnect that were not manually saved before disconnect will be lost; saving polygons before leaving the notebook unattended is consequently recommended. To resume work:\n",
        "\n",
        "1.   Identify the semi-automated processing run output directory (found in the '/outputs' sub-directory of your project directory) for the disconnected session. You will load polygons from this directory.\n",
        "2.   Reconnect to the notebook\n",
        "3.   (Optionally) clear cell outputs so that outputs from the previous session are not mixed with fresh outputs - see \"How to run this Notebook...\" above for instructions.\n",
        "4.   Re-run the notebook from the first code cell up to the semi-auto \"polygon loading\" cells, skipping automated processing.\n",
        "5.   Input the name of the disconnected output directory (step 1) into the second \"polygon loading\" cell, then run the cell to load all saved polygons from said directory.\n",
        "6.   Open the semi-automated segmentation GUI, then navigate to the sample that you left on and resume work.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0XrzkU09mP9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Possible Workflows:"
      ],
      "metadata": {
        "id": "jBkTjTKx17qi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Only using automated processing:\n",
        "Due to low but non-negligable automated segmentation error rates, this workflow is **not recommended for production of publication-quality measurements**, but can be used to quickly approximate aggregate grain size distributions for optimal samples (i.e., with good image quality and well-exposed grains).\n",
        "\n",
        "Steps:\n",
        "1. Run cells in 'Processing Option A' after running all required cells above. This is the only step.\n",
        "\n",
        "### Sample-by-sample semi-automated processing \n",
        "This workflow **can be used to produce publication-quality measurements** but requires that users wait while grains from each sample are segmented and is thus less efficient than the recommended workflow.\n",
        "\n",
        "Steps:\n",
        "1.   Run the GUI in 'Processing Option B' after running all required cells above, not including fully automated segmentation ('Processing Option B').\n",
        "2.   Produce and correct segmentations and measurements on a sample-by-sample basis\n",
        "\n",
        "### Automated segmentation followed by manual segmentation checking/editing\n",
        "This is the **recommended workflow for production of publication-quality measurements**.\n",
        "\n",
        "Steps:\n",
        "1. Run cells in 'Processing Option A' with polygon saving enabled after running all required cells above.\n",
        "2.   Load polygons and use the GUI ('Processing Option B') to check and/or edit auto-generated polygons. Can be done in a single sesssion or iteratively in multiple sessions; load polygons from your last semi-automated processing run to pick up where you left off."
      ],
      "metadata": {
        "id": "D-woZ0kv2FqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Data Formatting and Organization:"
      ],
      "metadata": {
        "id": "h6-ooPG62Umh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use this Notebook, a formatted project folder containing your data files must be uploaded to your Google Drive. A 'sample_info.csv' file with scaling information may be included in the folder if needed.\n",
        "\n",
        "Your project folder must be organized following a structure shown below (in 'Project Folder Organization Options'), depending on use-case. \n"
      ],
      "metadata": {
        "id": "q3xUNZWF2b2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project Folder Organization Options:"
      ],
      "metadata": {
        "id": "frPyk-vjivba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Option A: Sample information included in file names"
      ],
      "metadata": {
        "id": "ztcOBVyrhY7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this format if image (+/- .Align file) filenames contain sample names (e.g., saved images from UCSB have format 'ScanImage_ **SAMPLE_NAME** - **SHOT_NUMBER** ... .png'). In this case, sample names will be extracted and used to organize your dataset automatically during data loading. If your dataset does not have sample names, you can also use this option by simply adding all files to the 'scans' directory.\n",
        "\n",
        "A template project folder with this format that can be downloaded, edited, and re-uploaded is available [here](https://drive.google.com/drive/folders/1MkWh9PRArbV1m1eVbSTbb9C5PKC95Re3?usp=sharing).\n",
        "\n",
        "```\n",
        "root directory\n",
        "|   sample_info.csv*\n",
        "|\n",
        "└───scans\n",
        "│   │   XXX_SAMPLE-SCAN.png\n",
        "│   │   XXX_SAMPLE-SCAN.Align**\n",
        "│   │   YYY_SAMPLE-SCAN.png\n",
        "│   │   YYY_SAMPLE-SCAN.Align**\n",
        "|   |   ...\n",
        "|\n",
        "└───outputs***\n",
        "    |   ...\n",
        "\n",
        "*Optional; can be used to provide scaling info for datasets without .Align \n",
        " scaling metadata files. If neither are present, a scale of 1.0 μm/pixel will\n",
        " be assumed.\n",
        "\n",
        "**Optional; if present must have same names (except for file suffix) as\n",
        "  corresponding image files.\n",
        "\n",
        "***Optional; if this folder does not exist it will be automatically created\n",
        "   during processing\n",
        "```"
      ],
      "metadata": {
        "id": "S4EGnkpihyDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Option B: Dataset scan images organized into folders by sample"
      ],
      "metadata": {
        "id": "KnGfmduXh37A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this format if image (+/- .Align file) filenames do not contain sample names (e.g., images might have format '**SHOT_NUMBER** ... .png'). In this case, names of sub-folders containing scans will be used as sample names and used to organize your dataset automatically during data loading.\n",
        "\n",
        "A template project folder with this format that can be downloaded, edited, and re-uploaded is available [here](https://drive.google.com/drive/folders/1VpYo5HwDUaAQ4lJ0waZJRDrWkzHv2QyM?usp=sharing).\n",
        "\n",
        "\n",
        "```\n",
        "root directory\n",
        "|   sample_info.csv*\n",
        "|\n",
        "└───scans\n",
        "│   │\n",
        "│   └───SAMPLE_XXX\n",
        "│   │   │   SCAN-1.png\n",
        "│   │   │   SCAN-1.Align**\n",
        "│   │   │   SCAN-2.png\n",
        "│   │   │   SCAN-2.Align**\n",
        "|   |   │   ...\n",
        "│   │\n",
        "|   |───SAMPLE_YYY\n",
        "│   │   │   SCAN-1.png\n",
        "│   │   │   SCAN-1.Align**\n",
        "│   │   │   SCAN-2.png\n",
        "│   │   │   SCAN-2.Align**\n",
        "|   |   │   ...\n",
        "|   |   ...\n",
        "|\n",
        "|\n",
        "└───outputs***\n",
        "    |   ...\n",
        "\n",
        "*Optional; can be used to provide scaling info for datasets without .Align \n",
        " scaling metadata files. If neither are present, a scale of 1.0 μm/pixel will\n",
        " be assumed.\n",
        "\n",
        "**Optional; if present must have same names (except for file suffix) as\n",
        "  corresponding image files.\n",
        "\n",
        "***Optional; if this folder does not exist it will be automatically created\n",
        "   during processing\n",
        "```"
      ],
      "metadata": {
        "id": "vWLCMVRvi69Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sample_info.csv Formatting"
      ],
      "metadata": {
        "id": "98IjtM9t2oz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you include a sample_info csv file in your project folder, it must have headers (capitalization must match):\n",
        "\n",
        "| **Sample** | **Scale** |\n",
        "\n",
        "Data that should be entered under each of the headers will be as follows:\n",
        "\n",
        "\n",
        "*   **Sample**: Name of each sample, matchable either to scan names or to data subfolders, depending on directory organization (e.g., 'V26').\n",
        "*   **Scale**: Scale for images from a sample in μm/pixel.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "i-M2XN8D2utt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06yBm0pRreAd"
      },
      "source": [
        "## Setup and Installation:\n",
        "\n",
        "\n",
        "The 2 cells below (modified from the [Detectron2 Colab tutorial](https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5)) will install Detectron2 and import various packages neccesary for further processing. The runtime will automatically restart upon Detectron2 installation in the first cell. Note that said restart may prompt a crash warning - this is expected and the warning should be ignored.\n",
        "\n",
        "-  V1.0.8.1 (HOTFIX) notes: Detectron2 has yet to release a binary distribution matching the latest Colab-standard PyTorch distribution (V1.11). As of 05/19/2022, this breaks Colab Detectron2 installation. Workaround is to install Detectron2 from source, which takes significantly longer (i.e., several minutes) than binary installation but **does not require notebook restart**. You can safely ignore any warnings in the cell output; Detectron2 will be installed and functional despite these warnings. This will be fully fixed as soon as Facebook releases a compatible binary distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puL6ZbwlppA7"
      },
      "source": [
        "!pip install pyyaml==5.1\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "\n",
        "### Standard Detectron2 installation code below; \\\n",
        "### uncomment once D2 binary dist. is released for Torch V1.11.\n",
        "## Install detectron2 that matches the above pytorch version\n",
        "## See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "#!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
        "#exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s3s-2F8JmjI"
      },
      "source": [
        "# import some neccesary libraries\n",
        "import os, cv2, sys\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "%matplotlib auto\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import catalog\n",
        "\n",
        "#install colab_zirc_dims\n",
        "!pip install colab_zirc_dims==1.0.10\n",
        "\n",
        "#!python -m pip install  'git+https://github.com/MCSitar/colab_zirc_dims.git@v1_0_10'\n",
        "\n",
        "#import colab_zirc_dims modules\n",
        "from colab_zirc_dims import save_load\n",
        "from colab_zirc_dims import alc_notebook_fxns\n",
        "from colab_zirc_dims import zirc_dims_GUI\n",
        "from colab_zirc_dims import gen_notebook_fxns\n",
        "from colab_zirc_dims import gen_filename_fxns\n",
        "from colab_zirc_dims import expl_vis\n",
        "from colab_zirc_dims import non_std_cfgs\n",
        "#optionally import some functions to main IPython\n",
        "#kernel for local (non-Colab) compatability\n",
        "try:\n",
        "    from google.colab import output\n",
        "except ModuleNotFoundError:\n",
        "    from colab_zirc_dims.jupyter_colab_compat import output_local as outpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkqTw8-cjB3E"
      },
      "source": [
        "\n",
        "To mount your Google Drive, simply run the cell below and input your authentication code as requested."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcNfpP3BsJVE"
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "except ModuleNotFoundError:\n",
        "    print('Could not find google.colab.drive.',\n",
        "          'This is ok if notebook is not being run',\n",
        "          'in Google Colab')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhjGHLedsOhT"
      },
      "source": [
        "Modify the form field and run the cell below to set your project directory (organized as above) as the root directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYRKBqn9sNvZ"
      },
      "source": [
        "#@title Input full path to project folder here, then run this cell\n",
        "ROOT_DIR = \"/content/drive/My Drive/test_opt_a_import_folder\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6wy-6GJWXpY"
      },
      "source": [
        "## Data Loading:\n",
        "\n",
        "The cells below will allow you to select loading options and load your dataset into the notebook. The 'splitting fxn' parameter defines a function that is used to extract scan +/- sample names from image filenames, and a custom function can optionally be implemented here. See 'Data Formatting and Organization' above for more info on possible project directory structure and how to format a sample_info.csv scale file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define a custom function for extracting sample, scan info from file names (optional):"
      ],
      "metadata": {
        "id": "Vj4IX9Rll27E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your image filenames contain sample/scan info in a format that is not currently supported by this notebook (i.e., [not defined here](https://github.com/MCSitar/colab_zirc_dims/blob/main/colab_zirc_dims/gen_filename_fxns.py)), you can define a custom function for extracting this information from file names here and then run the cell. If you do write a custom function that works for datasets with a currently-unsupported file name format, please consider submitting a pull request or contacting the colab_zirc_dims project manager so that other users can use this function."
      ],
      "metadata": {
        "id": "XEeCz4Bhl_S6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#edit the function below\n",
        "def custom_name_split(filename):\n",
        "  ## Some code to extract a sample name string (can be a placeholder if\n",
        "  ## this info is not actually in file names) and scan name string from\n",
        "  ## the filename of each image in your dataset.\n",
        "  return 'PLACEHOLDER_SAMPLE_NAME', filename.strip('.png')\n",
        "\n",
        "name_splitting_fxs = {'UCSB': gen_filename_fxns.split_name_ucsb,\n",
        "                      'Custom function': custom_name_split,\n",
        "                      'Use full image file name': None}"
      ],
      "metadata": {
        "id": "qWaV4fTl0A4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset:\n",
        "Run the cell below to select options and load your dataset. Re-run this cell and the one below ('Select Samples') if you have made any changes to structure/files  (e.g., sample_info.csv) in your project directory since last running it.\n",
        "\n",
        "When dataset loading is complete, the cell will print \"Done\", and you can move on to the next cell."
      ],
      "metadata": {
        "id": "MilQv-fWmMkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_args_list = []\n",
        "loaded_data_dict = {}\n",
        "try:\n",
        "    gen_notebook_fxns.gen_data_load_interface(ROOT_DIR, load_args_list,\n",
        "                                              loaded_data_dict,\n",
        "                                              name_splitting_fxs)\n",
        "except NameError:\n",
        "    gen_notebook_fxns.gen_data_load_interface(ROOT_DIR, load_args_list,\n",
        "                                              loaded_data_dict,\n",
        "                                              gen_filename_fxns.default_name_fxns)"
      ],
      "metadata": {
        "id": "apA6piCrv5wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Selection:\n",
        "Run the cell below to select loaded samples for processing using dynamically-created checkboxes."
      ],
      "metadata": {
        "id": "964qwhY_s0EJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUDPgQLFWXpZ"
      },
      "source": [
        "#Selection of samples from dataset for processing\n",
        "selected_samples = []\n",
        "if len(list(loaded_data_dict.keys())):\n",
        "  alc_notebook_fxns.select_samples_fxn(loaded_data_dict, selected_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O682T15T0AxA"
      },
      "source": [
        "## Data Inspection (optional):\n",
        "Run the cell below to inspect (display random samples of images from each sample) selected data from each dataset in your project directory. Scales for\n",
        "images are in microns."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "gen_notebook_fxns.gen_inspect_data(loaded_data_dict,\n",
        "                                   selected_samples,\n",
        "                                   n_scans_sample = 3) #modify integer here to change\n",
        "                                                       # number of scans sampled from\n",
        "                                                       # each sample.\n",
        "%matplotlib auto"
      ],
      "metadata": {
        "id": "mw20ZRc0pa0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTxOTyV2WXpd"
      },
      "source": [
        "## Model Download and Initialization:\n",
        "\n",
        "The cells below will download (1st cell) and then initialize and configure (2nd cell) a trained grain-segmentation RCNN model; models were trained mainly on zircon grains but should be applicable to other heavy minerals. This model will be used to segment grains from the images that you previously loaded.\n",
        "\n",
        "Model training parameters and comparisons between model results and segmentations by humans can currently be found in our [preprint technical note](https://gchron.copernicus.org/preprints/gchron-2022-12/). You can find more information on new models on the colab_zirc_dims ['model library' page](https://github.com/MCSitar/colab_zirc_dims/blob/main/model_library.md). It is recommended that users pick one of the first two models, and that they avoid the last 3 models (these do not perform well and are only included for manuscript data replication purposes)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify path/url below if you want to use a custom (with downloadable models)\n",
        "# model library with this Notebook. Models are currently hosted for download on AWS;\n",
        "# see czd_model_library.json for direct download links and model lib formatting.\n",
        "\n",
        "#model_lib_loc = 'default' #this will get the current version of the czd model lib from Github\n",
        "model_lib_loc = 'https://raw.githubusercontent.com/MCSitar/colab_zirc_dims/v1_0_10/czd_model_library.json'\n",
        "\n",
        "current_model_dict = {}\n",
        "alc_notebook_fxns.select_download_model_interface(current_model_dict, model_lib_loc)"
      ],
      "metadata": {
        "id": "KEQM4ijgTQzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZzacbwXWXpd"
      },
      "source": [
        "# Run this cell after selecting a model in the cell above, and again if model is \\\n",
        "# changed at any point. Can be modified to load any Detectron 2 instance segmentation\\\n",
        "# model trained to detect grains.\n",
        "\n",
        "#define metadata 'grain' class for visualizations\n",
        "grain_metadata = catalog.Metadata(name='grain_meta', thing_classes=['grain'])\n",
        "\n",
        "#Load a predictor from config .yaml file and model weights.\n",
        "#Centermask2 and Swin-T dependencies are automatically installed if needed.\n",
        "predictor = non_std_cfgs.smart_load_predictor(\n",
        "    \n",
        "    #path to model config .yaml file\n",
        "    current_model_dict['selected_config_yaml'],\n",
        "    \n",
        "    #path to model weights\n",
        "    current_model_dict['selected_model_weights'],\n",
        "    \n",
        "    #defines whether model is run on CPU (very slow) or CUDA GPU\n",
        "    use_cpu=False,\n",
        "    \n",
        "    #sets model NMS threshold. If a float between 0 and 1, uses input float.\n",
        "    # If 'auto': uses empirically derived 'best' value for grain segmentation\n",
        "    # (0.2 for Mask-RCNN Resnet/Swin-T, 0.4 for Centermask2). If None, uses\n",
        "    # NMS threshold from config .yaml file.\n",
        "    adj_nms_thresh='auto',\n",
        "                                 \n",
        "    #sets model inference 'confidence' threshold. If a float between 0 and 1,\n",
        "    # uses input float. If 'auto': uses empirically derived 'best' value for\n",
        "    # grain segmentation (0.7 for Mask-RCNN Resnet/Swin-T, 0.5 for Centermask2).\n",
        "    # If None, uses NMS threshold from config .yaml file.\n",
        "    adj_thresh_test='auto')\n",
        "\n",
        "print('Predictor loaded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdiJZUitWXpe"
      },
      "source": [
        "## Test Evaluation (Optional):\n",
        "\n",
        "Run the cell below to visualize model prediction results on a random sample of scans from samples. Axes for scanned grain images will be in microns."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "gen_notebook_fxns.gen_demo_eval(selected_samples, loaded_data_dict, predictor, \n",
        "                                grain_metadata,\n",
        "                                n_scans_sample =3,#,#modify integer to change num. scans\n",
        "                                               # randomly selected, evaluated per sample.\n",
        "                                #src_str='2', #uncomment this line to only plot\n",
        "                                                #spots with this string in their\n",
        "                                                #scan name\n",
        "                                #fig_dpi=150, #uncomment to manually set dpi\n",
        "                                #show_legend=True #uncomment to plot legend\n",
        "                            )\n",
        "%matplotlib auto"
      ],
      "metadata": {
        "id": "hw_CWl4jrcd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVg-lhyQxgkZ"
      },
      "source": [
        "## Processing Option A: Fully Automated Processing:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below to automatically process all selected samples. Fully automated processing can be done alone or in combination with semi-automated processing - see the 'Workflows' section at top of this notebook.\n",
        "\n",
        "In the upper part of the cell, you will select alternate image pre-processing/segmentation methods to automatically try in case an initial attempt at segmentation fails. You do not have to select all or any of these alternate methods. Otsu thresholding segmentation (non-RCNN) is particularly sensitive to image artefacts and can produce wildly incorrect results.\n",
        "\n",
        "In the lower part of the cell, you will choose whether to save segmentation polygons (approximating autogenerated masks to within one micron) into .json files. These polygons can be loaded into GUI (see 'Option B' below) for evaluation and/or editing in this or any future Colab session. Saving polygons is recommended for verification purposes and enabled by default, but will slow down automated processing somewhat.\n",
        "\n",
        "After selecting alternate methods and choosing whether to save autogenrated polygons, run the cell to automatically process all selected samples. Grain dimensions will be saved to .csv files corresponding to each sample, and mask images will be saved as .png files for verification. If polygon saving is enabled, polygons will be saved into .json files for future editing or further verification."
      ],
      "metadata": {
        "id": "NWu2dDIo3J44"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CXrUeitxgkZ"
      },
      "source": [
        "#@title Select processing options, then run this cell to start fully automated proccessing\n",
        "#@markdown #####Alternate segmentation methods:\n",
        "Try_contrast_enhanced_subimage = True #@param {type:\"boolean\"}\n",
        "Try_Otsu_thresholding  = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown #####Save polygons for GUI viewing/editing?\n",
        "Save_polygons = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "save_polys_bool = Save_polygons\n",
        "alt_methods = [Try_contrast_enhanced_subimage,\n",
        "               Try_Otsu_thresholding]\n",
        "\n",
        "#@markdown ###### Identifying string for output directory name (can be blank):\n",
        "full_auto_str = '' #@param {type:\"string\"}\n",
        "\n",
        "#Below: actually run fully-automated segmentation for selected samples. \\\n",
        "#If somehow not set in cells above, mpl auto needed here to prevent RAM crash\n",
        "%matplotlib auto\n",
        "plt.switch_backend('Agg')\n",
        "run_dir = gen_notebook_fxns.full_auto_proc(ROOT_DIR, selected_samples, loaded_data_dict,\n",
        "                                           predictor, save_polys_bool, alt_methods,\n",
        "                                           full_auto_str, stream_output=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtuDo2R4ms4K"
      },
      "source": [
        "## Processing Option B: GUI (Semi-Automated) Processing:\n",
        "\n",
        "The cells below set up and open a simple GUI that allows sample-by-sample creation, inspection, replacement, and export of automatic grain segmentations. This may be most useful for images/samples that the automatic segmentation model struggles with (e.g., with poor image quality/misalignment or partially exposed grains). Semi-automated processing can be done alone or in combination with fully automated processing - see the 'Workflows' section at top of this notebook.\n",
        "_______________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load saved polygons (optional):"
      ],
      "metadata": {
        "id": "QatmrCJO3UCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step is optional. The GUI can be run without any loadable polygons and will in this case simply produce automated segmentations for each sample as the user navigates through their dataset. For efficient semi-automated processing (i.e., with minimal user wait times between samples), fully-automated segmentation and polygon loading is, however, recommended (see 'Workflows' above).\n",
        "\n",
        "(Optionally) running one of the two cells below allows loading polygons and limited metadata from a run directory created during a previous automated or semi-automated processing run. Polygons from the selected run directory will be copied to a current run directory, so segmentations can be edited iteratively in different sessions (see 'Workflows' above). Grain polygons will not be analyzed until the 'Analyze...' button is clicked in the GUI.\n",
        "\n",
        "*   Run the first cell below if you have just (within this notebook session) completed an automated processing run for your sample with polygon saving enabled and want to check/edit saved grain segmentations.\n",
        "*   OR\n",
        "*   Type in the folder name of a semi-automated or saving-enabled automated processing run subdirectory (e.g., *..project_dir/outputs/NAME_OF_RUN_DIRECTORY*) from this or a previous session to load polygons from it. Use this option if your runtime has disconnected since completing fully automated processing."
      ],
      "metadata": {
        "id": "_sm_94wM3WcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run this cell to attempt loading from a just-run automated processing run.\n",
        "try:\n",
        "  loading_dir = save_load.check_loadable(run_dir, verbose=True)\n",
        "except NameError:\n",
        "  print('No run_dir variable found for current session; try finding and manually',\n",
        "        ' adding a loadable run directory in the cell below or proceed without loading.')\n",
        "  loading_dir = None"
      ],
      "metadata": {
        "id": "2bQDWaCk-t-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OR"
      ],
      "metadata": {
        "id": "tIdd4J2spzjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add the name of a loadable run directory from this or a previous session, \\\n",
        "# then run this cell to attempt loading.\n",
        "input_loadable_run_dir = \"OUTPUT RUN FOR LOADING HERE\" #@param {type:\"string\"}\n",
        "loading_dir = save_load.check_loadable(os.path.join(ROOT_DIR, 'outputs',\n",
        "                                                    input_loadable_run_dir),\n",
        "                                       verbose=True)"
      ],
      "metadata": {
        "id": "nirosSG4qa9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Open and Run GUI\n"
      ],
      "metadata": {
        "id": "mH0iiaYc-sj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the cell below will actually open the GUI. If a valid previous run was selected, polygons will be loaded from that run. Otherwise, new automated segmentations will be produced on a sample-by-sample basis. Upon invoking the 'Analyze...' functions, grain dimensions will be saved to .csv files corresponding to each sample, mask images will be saved as .png files for verification, and any changes to polygons will be saved to .json files corresponding to each sample.\n",
        "\n",
        "Because Google Colab will automatically close inactive runtimes, it is recommended that users not leave GUI running but inactive without first saving changes. This is, of course, not a problem if you are running the notebook locally (i.e., not in Colab).\n",
        "\n",
        "\n",
        ">**Instructions and tips:**\n",
        ">\n",
        "> Click on the canvas to start a new grain polygon, and double click (keyboard shortcut: \"e\") to finish the polygon.\n",
        ">\n",
        ">The 'restore orig. polygon' button (keyboard shortcut: \"r\") will revert to the last saved automatically-generated (or, in the case of loaded polygons, possibly human-generated) grain segmentation if one exists.\n",
        ">\n",
        ">The 'tag scan' button (keyboard shortcut: \"t\") adds a tag to the scan that will persist into the exported image filename and grain dimensions .csv file. What this tag means is up to the user (e.g., well-exposed grains could be tagged).\n",
        ">\n",
        ">The 'Save changes to sample polygons' button will send all current polygons in the currently-open sample for .json saving. This will also be done automatically upon switching between samples or sending polygons for grain dimension analysis.\n",
        ">\n",
        ">The 'Analyze sample dimensions and export to Drive' button will send all current polygons in the currently-open sample for .json saving and dimensional analysis and save the results to your Google Drive project folder.\n",
        ">\n",
        ">The 'Analyze... all selected samples' button will measure dimensions of grains for all samples in the dataset where saved polygons (either generated in current session or loaded from a previous one) are available. For as-of-yet unclear reasons this is a slow process, so it may be best to check/edit all polygons in a dataset before starting it."
      ],
      "metadata": {
        "id": "AtUOqWxW3fqM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXyzx0humsdS"
      },
      "source": [
        "#run this cell to open GUI\n",
        "%matplotlib auto\n",
        "plt.switch_backend('Agg')\n",
        "try:\n",
        "  loading_dir = loading_dir\n",
        "except NameError:\n",
        "  loading_dir = None\n",
        "#@markdown ###### Identifying string for new output directory name (can be blank):\n",
        "semiauto_str = '' #@param {type:\"string\"}\n",
        "semi_run_dir = zirc_dims_GUI.run_gen_GUI(loaded_data_dict, selected_samples, ROOT_DIR, predictor,\n",
        "                                         loading_dir, semiauto_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory grain size/shape visualization (optional)\n",
        "\n",
        "Run the cell below to open a user-interface for exploratory visualization of colab_zirc_dims-exported measurement data with paramaterizable plots."
      ],
      "metadata": {
        "id": "AsUECGwA_b5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#try loading directories from current notebook; otherwise user will select\n",
        "# directory for visualization manually\n",
        "cur_run_dirs = []\n",
        "try:\n",
        "  cur_run_dirs.append(run_dir.split('/')[-1])\n",
        "except NameError:\n",
        "  cur_run_dirs.append(None)\n",
        "try:\n",
        "  cur_run_dirs.append(semi_run_dir.split('/')[-1])\n",
        "except NameError:\n",
        "  cur_run_dirs.append(None)\n",
        "\n",
        "%matplotlib inline\n",
        "try:\n",
        "    expl_vis.czd_expl_plot_ui(ROOT_DIR, *cur_run_dirs,\n",
        "                              selected_samples,\n",
        "                              default_include_strings = 'Spot')\n",
        "except Exception as e:\n",
        "    expl_vis.czd_expl_plot_ui(ROOT_DIR, None, None,\n",
        "                              selected_samples,\n",
        "                              default_include_strings = 'Spot')"
      ],
      "metadata": {
        "id": "-0EAEaw3_auB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}